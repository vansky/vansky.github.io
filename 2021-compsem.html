---
layout: page
title: Computational Seminar 2021
sidebar_link: false
order: 4
---

Neural networks have enabled amazing progress in natural language processing over the past decade. However, their linguistic representations have been repeatedly shown to simply exploit shallow statistical heuristics rather than actually learning the underlying linguistic patterns. This has sparked an active debate in natural language processing as to whether or not these models will ever be able to learn linguistic meaning, especially when most language models are trained solely on text data. In this seminar we will read and discuss a number of papers on cognitive theories of meaning, computational models of meaning, and statistical learning to look outside natural language processing for solutions to this dilemma.

<h3>Syllabus</h3>
<a href="/assets/pdf/compsem-syllabus-2021.pdf">pdf</a><br>

<h3>Schedule</h3>

<h4>Week 1: Poverty of the Stimulus</h4>
Syllabus<br>
<a href="https://www.aclweb.org/anthology/2020.acl-main.463/">Bender and Koller (2020). Climbing towards NLU</a><br>
<a href="https://www.aclweb.org/anthology/2020.acl-main.179/">Davis & van Schijndel (2020). Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment</a><br>
<a href="https://arxiv.org/abs/2004.10151">Bisk et al. (2020). Experience grounds language</a><br>

<h4>Week 2: Variability in Meaning</h4>
<a href="https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00293">Pavlick and Kwiatkowski (2019). Inherent Disagreements in Human Textual Inferences</a><br>

<h4>Week 3: Tracking Events</h4>
<a href="http://www.psycholinguistics.com/gerry_altmann/research/papers/files/IOH.pdf">Altmann & Ekves (2020). Events as intersecting object histories</a><br>

<h4>Week 3: Tracking Entities</h4>
<a href="https://www.aclweb.org/anthology/W19-2803.pdf">Kunz and Hardmeier (2019). Entity Decisions in Neural Language Modelling: Approaches and Problems</a><br>
<a href="https://www.aclweb.org/anthology/N18-1204.pdf">Clark et al. (2018). Neural Text Generation in Stories Using Entity Representations as Context</a><br>

<h4>Week 4: Informativity-Driven Saliency</h4>
<a href="http://www.lel.ed.ac.uk/~hrohde/papers/RohdeFutrellLucas.2020.pdf">Rohde et al. (2021). What's new? A comprehension bias in favor of informativity</a><br>
Michael: <a href="https://www.aclweb.org/anthology/2020.acl-main.442.pdf">Ribeiro et al. (2020). Beyond Accuracy: Behavioral Testing of NLP Models with CheckList</a><br>

<h4>Week 5: Disentangling Syntax and Semantics</h4>
<a href="https://www.aclweb.org/anthology/2020.acl-main.746.pdf">Stengel-Eskin et al. (2020). Universal Decompositional Semantic Parsing</a><br>
<a href="https://www.aclweb.org/anthology/2020.lrec-1.699.pdf">White et al. (2020). The Universal Decompositional Semantics Dataset and Decomp Toolkit</a><br>
Chih-Chan: <a href="https://www.aclweb.org/anthology/N19-1088.pdf">Romanov et al. (2019). Adversarial Decomposition of Text Representation</a><br>

<h4>Week 6: Symbolic vs Subsymbolic (Part 1)</h4>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0010027711003052">Feldman (2012). Symbolic representation of probabilistic worlds</a><br>

<h4>Week 7: Discourse Influences (Part 1)</h4>
<a href="https://www.tandfonline.com/doi/abs/10.1080/23273798.2021.1896013">Lee and Kaiser (2021). Does hitting the window break it?: Investigating effects of discourse-level and verb-level information in guiding object state representations</a><br>
Forrest: <a href="https://web.stanford.edu/~bresnan/Contractions-draft.pdf">Bresnan (2021). Formal grammar, usage probabilities, and English tensed auxiliary contraction</a><br>

<h4>Week 8: Discourse Influences (Part 2)</h4>
<a href="https://www.tandfonline.com/doi/full/10.1080/0163853X.2017.1330029">Clifton and Frazier (2018). Context Effects in Discourse: The Question Under Discussion</a><br>
Isa: <a href="https://www.aclweb.org/anthology/2020.acl-main.490.pdf">Mueller et al. (2020). Cross-Linguistic Syntactic Evaluation of Word Prediction Models</a><br>

<h4>Week 9: Symbolic vs Subsymbolic (Part 2a)</h4>
<a href="http://colala.berkeley.edu/papers/piantadosi2020computational.pdf">Piantadosi (2020). The Computational Origin of Representation (Sections 1-3)</a><br>
Joseph: <a href="https://arxiv.org/abs/2101.07668.pdf">Hengchen et al. (2021). Challenges for Computational Lexical Semantic Change</a><br>

<h4>Week 10: Symbolic vs Subsymbolic (Part 2b)</h4>
<a href="http://colala.berkeley.edu/papers/piantadosi2020computational.pdf">Piantadosi (2020). The Computational Origin of Representation (Sections 4-8)</a><br>
Kaelyn: Events in psycholinguistics and in language models</a><br>

<h4>Week 11: Wellness day</h4>

<h4>Week 12: Meaning from Form Revisited</h4>
<a href="http://arxiv.org/pdf/2104.10809.pdf">Merrill et al. (unpublished). Provable Limitations of Acquiring Meaning from Ungrounded Form: What will Future Language Models Understand?</a><br>
Will: <a href="https://www.aclweb.org/anthology/2020.conll-1.30.pdf">Rodriguez and Merlo (2020). Word associations and the distance properties of context-aware word embeddings</a><br>

<h4>Week 13</h4>
Project presentations<br>

<br><br>
<br><br>
